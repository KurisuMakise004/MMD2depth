{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#MMD2depth\n",
        "\n",
        "[MMD2depth](https://github.com/KurisuMakise004/MMD2depth) is a tool for converting [MikuMikuDance](https://sites.google.com/view/vpvp) models (.pmx) with motions(.vmd) to depth images sequences for use with depth2img scripts in [Stable Diffusion 2.0](https://github.com/KurisuMakise004/stablediffusion).\n",
        "\n",
        "This tool is based on the [MMD2UDP](https://github.com/KurisuMakise004/MMD2UDP), which converts MMD to [UltraDensePose](https://github.com/transpchan/transpchan.github.io/blob/57efe17cdce35cf2c49c8d11ebd9bac108d1ac59/live3d/CoNR.pdf). "
      ],
      "metadata": {
        "id": "Tqd3vAfzIfSI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGA8rrLbbxx-",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install packages\n",
        "%cd /content/\n",
        "!apt install ca-certificates \\\n",
        "software-properties-common \\\n",
        "&& add-apt-repository -y ppa:savoury1/ffmpeg4 >/dev/null \\\n",
        "&& add-apt-repository -y ppa:savoury1/display >/dev/null\n",
        "!apt install ffmpeg wget curl\n",
        "!wget https://github.com/KurisuMakise004/MMD2depth/raw/main/MMD2depth_linux.7z"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload your `model.zip`, `motion.vmd`, and `camera.vmd` to `/content/`\n",
        "\n",
        "#@markdown `model.zip` **must be a ZIP archive** with with all your MMD files (your_model.pmx/vrm, and textures). \n",
        "\n",
        "#@markdown Note that tar, 7z, rar, or other formats are **not** supported at the moment."
      ],
      "metadata": {
        "cellView": "form",
        "id": "1mWGGGsdaWWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate depth sequence\n",
        "\n",
        "#@markdown Output will be placed at `/content/udp/output` \n",
        "\n",
        "#@markdown  The process might take very long for models with complicated physics setups, as the conversion process need to go through your motion.vmd and compute for each frame to obtain an depth sequence.\n",
        "\n",
        "%cd /content/\n",
        "!rm -r ./udp\n",
        "!7z x ./MMD2depth_linux.7z\n",
        "!cp model.zip ./udp/\n",
        "!cp motion.vmd ./udp/\n",
        "!cp camera.vmd ./udp/\n",
        "!cd ./udp/ && chmod +x ./udp && ./udp"
      ],
      "metadata": {
        "id": "_kJJT7IstJJ7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save the depth as numpy array\n",
        "\n",
        "#@markdown You can then load `/content/depth.npy` in Stable Diffusion to generate your drawings.\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"] = \"1\"\n",
        "depth = cv2.imread(\"./udp/output/0001\",  cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH | cv2.IMREAD_UNCHANGED)\n",
        "np.save(\"./depth\", depth)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "D72KymLCGMzI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
